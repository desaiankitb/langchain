{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Q&A over Documents\n",
    "\n",
    "An example might be a tool that would allow you to query a product catalog for items of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10c1f7b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start by importing the environment variables as we always do \n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead635a0-42e2-46cc-a9f7-98419eceae6d",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc533037-0b8c-4995-96a3-45b35fa13c18",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "# this block just initialises `llm_model` variable nothing else\n",
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b5f06",
   "metadata": {},
   "source": [
    "Now we're going to import some things that will help us when building this chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# We're going to import the retrieval QA chain. This will do retrieval over some documents. \n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# We're going to import our favorite chat open AI language model.\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# We're going to import a document loader. This is going to be used to load some proprietary data that \n",
    "# we're going to combine with the language model. \n",
    "# In this case it's going to be in a CSV. So we're going to import the CSV loader.\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "# Finally, we're going to import a vector store. \n",
    "# There are many different types of vector stores and we'll cover what exactly these are later on but we're going to get started with the \"DocArrayInMemorySearch\" vector store. \n",
    "# This is really nice because it's an in-memory vector store and it doesn't require connecting to an external database of any kind so it makes it really easy to get started.\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "#  We're also going to import display and markdown to common utilities for displaying information in our notebooks.\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7249846e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# We've provided a CSV of outdoor clothing that we're going to use to combine with the language model. \n",
    "# Here we're going to initialize a loader, the CSV loader, with a path to the file.\n",
    "file = '../data/OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfaba30",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# We're next going to import an index, the \"VectorStoreIndexCreator\". \n",
    "# This will help us create a vector store really easily.\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b5ab657",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e200726",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/kbclh8y12dz3_njd9xrldcm80000gp/T/ipykernel_83230/3306042312.py:8: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings()\n",
      "/usr/local/genuin/code/personal/langchain/.venv/lib/python3.12/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# To create an index, we're going to specify two things. \n",
    "# First, we're going to specify the vector store class. \n",
    "# As mentioned before, we're going to use this vector store, as it's a particularly easy one to get started with. \n",
    "# After it's been created, we're then going to call \"from_loaders\", which takes in a list of document loaders. \n",
    "# We've only got one loader that we really care about, so that's what we're passing in here. \n",
    "# It's now been created and we can start to ask questions about it.\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embedding_model\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34562d81",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Below we'll cover what exactly happened under the hood, \n",
    "# so let's not worry about that for now. Here, we'll start with a query.\n",
    "query =\"Please list all your shirts with sun protection \\\n",
    "in a table in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4c615-d6e4-4dd6-bc53-a9c46df7276c",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- The notebook uses `langchain==0.0.179` and `openai==0.27.7`\n",
    "- For these library versions, `VectorstoreIndexCreator` uses `text-davinci-003` as the base model, which has been deprecated since 1 January 2024.\n",
    "- The replacement model, `gpt-3.5-turbo-instruct` will be used instead for the `query`.\n",
    "- The `response` format might be different than the class because of this replacement model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd0cc37",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/kbclh8y12dz3_njd9xrldcm80000gp/T/ipykernel_83230/2409598586.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm_replacement_model = OpenAI(temperature=0,\n"
     ]
    }
   ],
   "source": [
    "llm_replacement_model = OpenAI(temperature=0, \n",
    "                               model='gpt-3.5-turbo-instruct')\n",
    "\n",
    "# We'll then create a response using \"index.query\" and pass in this query.\n",
    "response = index.query(query, \n",
    "                       llm = llm_replacement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae21f1ff",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| Name | Description | Sun Protection Rating |\n",
       "| --- | --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Made of 100% polyester, UPF 50+ rating, wrinkle-resistant, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | Made of 52% polyester and 48% nylon, UPF 50+ rating, SunSmart technology, wrinkle-free, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | Made of 71% nylon and 29% polyester, UPF 50+ rating, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Sun Shield Shirt | Made of 78% nylon and 22% Lycra Xtra Life fiber, UPF 50+ rating, moisture-wicking, abrasion-resistant, fits over swimsuit | SPF 50+, blocks 98% of harmful UV rays |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Again, we'll cover what's going on under the hood down below. \n",
    "# We've gotten back a table in markdown with names and descriptions for all shirts with sun protection. \n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73440989",
   "metadata": {},
   "source": [
    "goto: slide #21, 22, 23, 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534597e-4b0c-4563-a208-e2dd91064438",
   "metadata": {},
   "source": [
    "## Step By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631396c6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# So above, we created this chain and only a few lines of code. \n",
    "# But let's now do it a bit more step-by-step and understand what exactly is going on under the hood. \n",
    "# The first step is similar to above. \n",
    "# We're going to create a document loader, loading from that CSV with all the descriptions of the products that we want to do question answering over.\n",
    "from langchain.document_loaders import CSVLoader\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c2164b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# We can then load documents from this document loader. \n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a977f44",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/OutdoorClothingCatalog_1000.csv', 'row': 0}, page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we look at the individual documents, we can see that each document corresponds to one of the products in the CSV. \n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e875693a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Previously, we talked about creating chunks. \n",
    "# Because these documents are already so small, we actually don't need to do any chunking here. \n",
    "# And so we can create embeddings directly. \n",
    "# To create embeddings, we're going to use OpenAI's embedding class.\n",
    "# We can import it and initialize it here.\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "779bec75",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    " # If we want to see what these embeddings do, we can actually take a look at what happens when we embed a particular piece of text. \n",
    "embed = embeddings.embed_query(\"Hi my name is Ankit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "699aaaf9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "# In this case, the sentence, \"Hi, my name is Ankit.\" \n",
    "# If we take a look at this embedding, we can see that there are over a thousand different elements.\n",
    "print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d00d346",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.010378659221592458, 0.0007889397309350342, -0.0179676963998228, -0.014404589573688809, -0.016902568897655755]\n"
     ]
    }
   ],
   "source": [
    "# Each of these elements is a different numerical value.\n",
    "# Combined, this creates the overall numerical representation for this piece of text.\n",
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27ad0bb0",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# We want to create embeddings for all the pieces of text that we just loaded and then we also want to store them in a vector store.\n",
    "# We can do that by using the \"from_documents\" method on the vector store. \n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")\n",
    "# This method takes in a list of documents, an embedding object, and then we'll create an overall vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0329bfd5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# We can now use this vector store to find pieces of text similar to an incoming query. \n",
    "# So let's look at the query, \"Please suggest a shirt with sunblocking\". \n",
    "query = \"Please suggest a shirt with sunblocking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7909c6b7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# If we use the similarity search method on the vector store and pass in a query, we will get back a list of documents. \n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43321853",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eba90b5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/OutdoorClothingCatalog_1000.csv', 'row': 255}, page_content=': 255\\nname: Sun Shield Shirt by\\ndescription: \"Block the sun, not the fun – our high-performance sun shirt is guaranteed to protect from harmful UV rays. \\n\\nSize & Fit: Slightly Fitted: Softly shapes the body. Falls at hip.\\n\\nFabric & Care: 78% nylon, 22% Lycra Xtra Life fiber. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\\n\\nAdditional Features: Wicks moisture for quick-drying comfort. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. Imported.\\n\\nSun Protection That Won\\'t Wear Off\\nOur high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun\\'s harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that it returns four documents, and if we look at the first one, we can see that it is indeed a shirt about sunblocking. \n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306ba62",
   "metadata": {},
   "source": [
    "So, how do we use this to do question answering over our own documents? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0c3596e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# First, we need to create a retriever from this vector store.\n",
    "# A retriever is a generic interface that can be underpinned by any method that takes in a query and returns documents. \n",
    "# Vector stores and embeddings are one such method to do so, although there are plenty of different methods, some less advanced, some more advanced. \n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0625f5e8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/kbclh8y12dz3_njd9xrldcm80000gp/T/ipykernel_83230/2312143428.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n"
     ]
    }
   ],
   "source": [
    "# Next, because we want to do text generation and return a natural language response, \n",
    "# we're going to import a language model and we're going to use ChatOpenAI.\n",
    "\n",
    "llm_model = \"gpt-4o\"\n",
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a573f58a",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# If we were doing this by hand, what we would do is we would combine the documents into a single piece of text. \n",
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14682d95",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/kbclh8y12dz3_njd9xrldcm80000gp/T/ipykernel_83230/749327496.py:5: LangChainDeprecationWarning: The method `BaseChatModel.call_as_llm` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm.call_as_llm(f\"{qdocs} Question: Please list all your \\\n"
     ]
    }
   ],
   "source": [
    "# So we'd do something like this, where we join all the page content in the documents into a variable \n",
    "# and then would pass this variable or a variant on the question, like, \n",
    "# \"Please list all your shirts with sun protection in a table in markdown and summarize each one.\" into the language model. \n",
    "# let's call the model\n",
    "response = llm.call_as_llm(f\"{qdocs} Question: Please list all your \\\n",
    "shirts with sun protection in a table in markdown and summarize each one.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bba545b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is a markdown table summarizing the shirts with sun protection:\n",
       "\n",
       "| Name                               | Description                                                                                                           | Size & Fit                  | Fabric & Care                                                                 | Additional Features                                                                 |\n",
       "|------------------------------------|-----------------------------------------------------------------------------------------------------------------------|-----------------------------|--------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|\n",
       "| Sun Shield Shirt                   | High-performance sun shirt with UPF 50+ protection, blocks 98% of harmful UV rays.                                     | Slightly Fitted             | 78% nylon, 22% Lycra Xtra Life fiber. Handwash, line dry.                      | Moisture-wicking, abrasion-resistant, fits over swimsuits. Recommended by The Skin Cancer Foundation. |\n",
       "| Men's Plaid Tropic Shirt           | Ultracomfortable shirt with UPF 50+ protection, originally designed for fishing, great for travel.                     | Not specified               | 52% polyester, 48% nylon. Machine washable and dryable.                        | Wrinkle-free, quick-drying, front and back cape venting, two front bellows pockets.  |\n",
       "| Men's TropicVibe Shirt             | Lightweight sun-protection shirt with UPF 50+, ideal for hot weather and strong UV rays.                               | Traditional Fit             | Shell: 71% Nylon, 29% Polyester. Lining: 100% Polyester knit mesh. Machine wash and dry. | Wrinkle-resistant, front and back cape venting, two front bellows pockets.           |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Lightest hot-weather shirt with UPF 50+ protection, relaxed fit, made of 100% polyester.                                | Traditional Fit             | 100% polyester. Wrinkle-resistant.                                             | Front and back cape venting, two front bellows pockets.                              |\n",
       "\n",
       "### Summary:\n",
       "- **Sun Shield Shirt**: Offers high-performance sun protection with a slightly fitted design, moisture-wicking, and abrasion resistance. Ideal for wearing over swimsuits.\n",
       "- **Men's Plaid Tropic Shirt**: Designed for fishing and travel, this shirt is ultracomfortable with quick-drying and wrinkle-free features.\n",
       "- **Men's TropicVibe Shirt**: Provides lightweight sun protection with a traditional fit, perfect for hot weather with its venting features.\n",
       "- **Men's Tropical Plaid Short-Sleeve Shirt**: The lightest option for hot weather, offering a relaxed fit and excellent sun protection with venting for cool breezes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And if we print out the response here, we can see that we get back a table exactly as we asked for. \n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32c94d22",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# All these steps can be encapsulated with a langchain chain.\n",
    "# so we are creating a RetrievalQA chain\n",
    "# This does retrival and does question answering over the retrived document. \n",
    "# To create such chain we will pass in a few different things: \n",
    "# 1st: language model - will be used for text generation in the end. \n",
    "# 2nd: chain type - will be using the simplest method - it will stuff all the docs in to context and makes one call to a language model \n",
    "# 3rd: the retriver -  will be used to fetch the docs and pass it to the language model. \n",
    "\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4769316",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# create a query \n",
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc3c2f3",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/kbclh8y12dz3_njd9xrldcm80000gp/T/ipykernel_83230/2968830482.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_stuff.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# run the chain on this query \n",
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fba1a5db",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a table summarizing the shirts with sun protection:\n",
       "\n",
       "| Name                                      | Summary                                                                                                                                                                                                 |\n",
       "|-------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt   | A lightweight, wrinkle-resistant shirt made of 100% polyester, offering UPF 50+ sun protection. It features front and back cape venting and two front bellows pockets. Ideal for hot weather.             |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve    | Designed for fishing, this shirt is made of 52% polyester and 48% nylon, providing UPF 50+ protection. It is wrinkle-free, quick-drying, and includes cape venting and two front bellows pockets.         |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve      | This shirt offers a traditional fit with a shell of 71% nylon and 29% polyester, and a 100% polyester knit mesh lining. It provides UPF 50+ protection, is wrinkle-resistant, and features cape venting.    |\n",
       "| Sun Shield Shirt                          | Made of 78% nylon and 22% Lycra Xtra Life fiber, this shirt is slightly fitted and offers UPF 50+ protection. It wicks moisture, is abrasion-resistant, and fits comfortably over a swimsuit.              |\n",
       "\n",
       "Each shirt provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "500ec062",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# same thing as above -- both equates to the same thing. \n",
    "#  That's what makes the Langchain instresting -- you can exec in one line or you can breakdown the things step by step \n",
    "response = index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cffb19f",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings,\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45fbf8a",
   "metadata": {},
   "source": [
    "goto: slide #25 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
